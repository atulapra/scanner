{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cdfcdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next detailed file : unusual_options_scan_2025-12-11_2.csv\n",
      "Next summary file  : unusual_options_scan_2025-12-11_2_summary.csv\n",
      "[  1/170] ANSS — no matches\n",
      "[  2/170] ATVI — no matches\n",
      "[  3/170] AEP — no matches\n",
      "[  4/170] ALK — no matches\n",
      "[  5/170] AZN — no matches\n",
      "[  6/170] A — no matches\n",
      "[  7/170] ADSK — no matches\n",
      "[  8/170] AVAV — no matches\n",
      "[  9/170] AFRM — no matches\n",
      "[ 10/170] ✅ AMZN — found 3 matches\n",
      "[ 11/170] ADI — no matches\n",
      "[ 12/170] ABNB — no matches\n",
      "[ 13/170] AMGN — no matches\n",
      "[ 14/170] ✅ AAPL — found 5 matches\n",
      "[ 15/170] AMAT — no matches\n",
      "[ 16/170] ALAB — no matches\n",
      "[ 17/170] ✅ AMD — found 8 matches\n",
      "[ 18/170] ADP — no matches\n",
      "[ 19/170] ASML — no matches\n",
      "[ 20/170] ALGN — no matches\n",
      "[ 21/170] ✅ ADBE — found 2 matches\n",
      "[ 22/170] BKR — no matches\n",
      "[ 23/170] BA — no matches\n",
      "[ 24/170] ✅ AVGO — found 7 matches\n",
      "[ 25/170] ✅ BABA — found 3 matches\n",
      "[ 26/170] CE — no matches\n",
      "[ 27/170] BMRN — no matches\n",
      "[ 28/170] CFLT — no matches\n",
      "[ 29/170] CHKP — no matches\n",
      "[ 30/170] BBAI — no matches\n",
      "[ 31/170] ✅ BIDU — found 2 matches\n",
      "[ 32/170] CSGP — no matches\n",
      "[ 33/170] CTSH — no matches\n",
      "[ 34/170] BKNG — no matches\n",
      "[ 35/170] ✅ CCJ — found 1 matches\n",
      "[ 36/170] ✅ CEG — found 1 matches\n",
      "[ 37/170] ✅ CHWY — found 1 matches\n",
      "[ 38/170] FI — no matches\n",
      "[ 39/170] CHTR — no matches\n",
      "[ 40/170] CDNS — no matches\n",
      "[ 41/170] ✅ COST — found 3 matches\n",
      "[ 42/170] ✅ COIN — found 1 matches\n",
      "[ 43/170] ✅ CSCO — found 1 matches\n",
      "[ 44/170] EXC — no matches\n",
      "[ 45/170] CSX — no matches\n",
      "[ 46/170] ✅ CRWD — found 3 matches\n",
      "[ 47/170] EXEL — no matches\n",
      "[ 48/170] ✅ CRWV — found 1 matches\n",
      "[ 49/170] CTAS — no matches\n",
      "[ 50/170] ✅ DASH — found 1 matches\n",
      "[ 51/170] ✅ DELL — found 1 matches\n",
      "[ 52/170] DDOG — no matches\n",
      "[ 53/170] GKOS — no matches\n",
      "[ 54/170] DXCM — no matches\n",
      "[ 55/170] CRML — no matches\n",
      "[ 56/170] EA — no matches\n",
      "[ 57/170] ✅ DOCU — found 2 matches\n",
      "[ 58/170] ✅ FCX — found 6 matches\n",
      "[ 59/170] IDXX — no matches\n",
      "[ 60/170] JEF — no matches\n",
      "[ 61/170] KDP — no matches\n",
      "[ 62/170] GILD — no matches\n",
      "[ 63/170] GSK — no matches\n",
      "[ 64/170] FTNT — no matches\n",
      "[ 65/170] ✅ GEV — found 2 matches\n",
      "[ 66/170] ✅ GS — found 5 matches\n",
      "[ 67/170] ✅ GOOG — found 6 matches\n",
      "[ 68/170] ✅ HIMS — found 2 matches\n",
      "[ 69/170] KLAC — no matches\n",
      "[ 70/170] ✅ GOOGL — found 2 matches\n",
      "[ 71/170] HON — no matches\n",
      "[ 72/170] LENZ — no matches\n",
      "[ 73/170] ✅ HOOD — found 11 matches\n",
      "[ 74/170] LIN — no matches\n",
      "[ 75/170] ✅ INTC — found 3 matches\n",
      "[ 76/170] ✅ JD — found 2 matches\n",
      "[ 77/170] ✅ INTU — found 1 matches\n",
      "[ 78/170] ✅ JPM — found 3 matches\n",
      "[ 79/170] ISRG — no matches\n",
      "[ 80/170] ✅ JNJ — found 5 matches\n",
      "[ 81/170] METC — no matches\n",
      "[ 82/170] MNST — no matches\n",
      "[ 83/170] KSS — no matches\n",
      "[ 84/170] MTSR — no matches\n",
      "[ 85/170] LCID — no matches\n",
      "[ 86/170] ✅ MAR — found 3 matches\n",
      "[ 87/170] ✅ LLY — found 9 matches\n",
      "[ 88/170] MTCH — no matches\n",
      "[ 89/170] ✅ LULU — found 7 matches\n",
      "[ 90/170] MDLZ — no matches\n",
      "[ 91/170] LRCX — no matches\n",
      "[ 92/170] MCHP — no matches\n",
      "[ 93/170] MDB — no matches\n",
      "[ 94/170] NTES — no matches\n",
      "[ 95/170] NTLA — no matches\n",
      "[ 96/170] NNN — no matches\n",
      "[ 97/170] ✅ MP — found 1 matches\n",
      "[ 98/170] LVS — no matches\n",
      "[ 99/170] ✅ MRNA — found 3 matches\n",
      "[100/170] ✅ MSFT — found 3 matches\n",
      "[101/170] MELI — no matches\n",
      "[102/170] ODFL — no matches\n",
      "[103/170] ✅ MRVL — found 1 matches\n",
      "[104/170] ✅ META — found 7 matches\n",
      "[105/170] ✅ MU — found 1 matches\n",
      "[106/170] NEE — no matches\n",
      "[107/170] ORLY — no matches\n",
      "[108/170] ✅ MSTR — found 11 matches\n",
      "[109/170] PAYX — no matches\n",
      "[110/170] PCAR — no matches\n",
      "[111/170] NXPI — no matches\n",
      "[112/170] OKTA — no matches\n",
      "[113/170] ✅ NFLX — found 7 matches\n",
      "[114/170] ✅ QURE — found 1 matches\n",
      "[115/170] ONON — no matches\n",
      "[116/170] OKLO — no matches\n",
      "[117/170] ✅ NVDA — found 7 matches\n",
      "[118/170] ✅ OSCR — found 4 matches\n",
      "[119/170] ✅ ORCL — found 27 matches\n",
      "[120/170] PANW — no matches\n",
      "[121/170] PEP — no matches\n",
      "[122/170] ✅ PDD — found 4 matches\n",
      "[123/170] PINS — no matches\n",
      "[124/170] ✅ PLTR — found 10 matches\n",
      "[125/170] ✅ QCOM — found 1 matches\n",
      "[126/170] ✅ QBTS — found 1 matches\n",
      "[127/170] ✅ PYPL — found 2 matches\n",
      "[128/170] QS — no matches\n",
      "[129/170] ROP — no matches\n",
      "[130/170] REGN — no matches\n",
      "[131/170] SPLK — no matches\n",
      "[132/170] QUBT — no matches\n",
      "[133/170] ✅ RGTI — found 3 matches\n",
      "[134/170] ✅ RH — found 3 matches\n",
      "[135/170] ✅ RIVN — found 19 matches\n",
      "[136/170] ✅ RKLB — found 11 matches\n",
      "[137/170] ✅ ROKU — found 2 matches\n",
      "[138/170] ROST — no matches\n",
      "[139/170] ✅ SATS — found 1 matches\n",
      "[140/170] ✅ SBET — found 1 matches\n",
      "[141/170] ✅ SHOP — found 1 matches\n",
      "[142/170] SBUX — no matches\n",
      "[143/170] SIRI — no matches\n",
      "[144/170] VIX — no matches\n",
      "[145/170] ✅ SNDK — found 1 matches\n",
      "[146/170] TREX — no matches\n",
      "[147/170] ✅ SNPS — found 4 matches\n",
      "[148/170] ✅ SNOW — found 1 matches\n",
      "[149/170] STZ — no matches\n",
      "[150/170] SYM — no matches\n",
      "[151/170] VRSK — no matches\n",
      "[152/170] SPOT — no matches\n",
      "[153/170] ✅ SMCI — found 6 matches\n",
      "[154/170] TEAM — no matches\n",
      "[155/170] ✅ TMQ — found 1 matches\n",
      "[156/170] VRSN — no matches\n",
      "[157/170] WWW — no matches\n",
      "[158/170] TEM — no matches\n",
      "[159/170] XEL — no matches\n",
      "[160/170] TMUS — no matches\n",
      "[161/170] ✅ TSM — found 3 matches\n",
      "[162/170] ✅ TSLA — found 15 matches\n",
      "[163/170] VRTX — no matches\n",
      "[164/170] TXN — no matches\n",
      "[165/170] USAR — no matches\n",
      "[166/170] WDAY — no matches\n",
      "[167/170] ✅ UNH — found 5 matches\n",
      "[168/170] UPST — no matches\n",
      "[169/170] ZS — no matches\n",
      "[170/170] XYZ — no matches\n",
      "\n",
      "Saved 281 detailed rows → unusual_options_scan_2025-12-11_2.csv\n",
      "Saved 66 ticker summaries → unusual_options_scan_2025-12-11_2_summary.csv\n",
      "\n",
      "=== Top 25 tickers by total volume (summary) ===\n",
      "ticker  call_strike_min  call_strike_max  call_volume_sum  call_oi_sum  put_strike_min  put_strike_max  put_volume_sum  put_oi_sum  call_oi_2w_inc_avg  put_oi_2w_inc_avg  call_put_vol_ratio  call_put_oi_ratio  call_n_contracts  put_n_contracts  total_volume  total_oi\n",
      "  NVDA            182.5            182.5         141927.0      19945.0            90.0           180.0        272196.0     75208.0                 NaN                NaN            0.521415           0.265198               1.0              6.0      414123.0   95153.0\n",
      "  ORCL            205.0            217.5          55612.0       4920.0            70.0           195.0        219122.0     64358.0                 NaN           2.210458            0.253795           0.076447               5.0             22.0      274734.0   69278.0\n",
      "  TSLA            455.0            760.0         106307.0      31079.0           250.0           437.5        122536.0     34612.0           10.666667           0.194261            0.867557           0.897926               6.0              9.0      228843.0   65691.0\n",
      "  AAPL            280.0            282.5         126291.0      42583.0           272.5           277.5         91203.0     21144.0            0.255073           0.292039            1.384724           2.013952               2.0              3.0      217494.0   63727.0\n",
      "  RIVN             16.0             23.0          93787.0      20013.0            12.5            16.5         47033.0     12750.0                 NaN           8.003846            1.994068           1.569647              12.0              7.0      140820.0   32763.0\n",
      "  PLTR            192.5            202.5          22282.0       9352.0           100.0           185.0         94440.0     28526.0            3.170987           0.572385            0.235938           0.327841               3.0              7.0      116722.0   37878.0\n",
      "  HOOD            125.0            134.0         101257.0      16708.0           100.0           122.0          2407.0      1105.0                 NaN                NaN           42.067719          15.120362               9.0              2.0      103664.0   17813.0\n",
      "   AMD            255.0            255.0           1165.0        509.0           200.0           215.0         90862.0     26685.0                 NaN           0.631159            0.012822           0.019074               1.0              7.0       92027.0   27194.0\n",
      "  MSTR            215.0            540.0          35098.0       9804.0           105.0           177.5         46526.0     16379.0                 NaN                NaN            0.754374           0.598571               4.0              7.0       81624.0   26183.0\n",
      "  NFLX             93.5             99.5          72536.0      22545.0            94.5            94.5          3555.0      1728.0            4.975676           4.497349           20.403938          13.046875               6.0              1.0       76091.0   24273.0\n",
      "  META            660.0            890.0          36543.0      13503.0           640.0           640.0          8133.0      3302.0                 NaN                NaN            4.493176           4.089340               6.0              1.0       44676.0   16805.0\n",
      "  AMZN            230.0            230.0          22622.0       9782.0           217.5           227.5         15466.0      6372.0                 NaN          -0.053029            1.462692           1.535154               1.0              2.0       38088.0   16154.0\n",
      "  GOOG            317.5            332.5          19341.0       7029.0           280.0           310.0         14950.0      6452.0                 NaN                NaN            1.293712           1.089430               3.0              3.0       34291.0   13481.0\n",
      "  RKLB             64.0             70.0           8667.0       2366.0            56.0            63.0         10464.0      1222.0            3.981949           5.833333            0.828268           1.936170               4.0              7.0       19131.0    3588.0\n",
      "  AVGO            460.0            525.0           7283.0       3305.0           300.0           360.0         11765.0      4448.0            4.482289                NaN            0.619040           0.743031               4.0              3.0       19048.0    7753.0\n",
      "  MRNA             31.0             33.0          10320.0       2487.0            28.0            28.0          5102.0       138.0                 NaN                NaN            2.022736          18.021739               2.0              1.0       15422.0    2625.0\n",
      "   JNJ            212.5            220.0           2949.0        237.0           205.0           207.5          6511.0      1539.0                 NaN                NaN            0.452926           0.153996               3.0              2.0        9460.0    1776.0\n",
      "  LULU            222.5            250.0           6711.0       1497.0           135.0           147.0          2669.0      1117.0                 NaN                NaN            2.514425           1.340197               5.0              2.0        9380.0    2614.0\n",
      "   LLY           1030.0           1047.5           4721.0        755.0           960.0           990.0          4313.0      1559.0                 NaN                NaN            1.094598           0.484285               4.0              5.0        9034.0    2314.0\n",
      "  INTC             39.5             52.0           5286.0       1406.0            39.0            39.0          3526.0       901.0           17.575758                NaN            1.499149           1.560488               2.0              1.0        8812.0    2307.0\n",
      "   FCX             49.0             50.0           5481.0        466.0            47.0            48.0          2319.0        84.0                 NaN                NaN            2.363519           5.547619               3.0              3.0        7800.0     550.0\n",
      "  MSFT            520.0            520.0           1845.0        647.0           370.0           477.5          4369.0      1513.0                 NaN           0.440120            0.422293           0.427627               1.0              2.0        6214.0    2160.0\n",
      "    JD             30.0             30.0           3054.0        484.0            29.0            29.0          3079.0       640.0                 NaN                NaN            0.991880           0.756250               1.0              1.0        6133.0    1124.0\n",
      "    GS            930.0            965.0           1710.0        273.0           885.0           900.0          4245.0       138.0                 NaN                NaN            0.402827           1.978261               2.0              3.0        5955.0     411.0\n",
      "   UNH            342.5            360.0           4726.0       1789.0           332.5           332.5           718.0       198.0                 NaN                NaN            6.582173           9.035354               4.0              1.0        5444.0    1987.0\n",
      "\n",
      "=== Old-style Top 10 tickers by max score ===\n",
      " NVDA  score=1009941.0\n",
      " ORCL  score=568658.9\n",
      " SMCI  score=475928.1\n",
      "   GS  score=403225.0\n",
      " AAPL  score=260843.0\n",
      " TSLA  score=250025.4\n",
      " RIVN  score=212244.4\n",
      " PLTR  score=191998.6\n",
      " MRNA  score=188626.1\n",
      "  AMD  score=167826.6\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ------------------ USER SETTINGS ------------------\n",
    "MAX_EXPIRIES_PER_TICKER = 8\n",
    "LAST_PRICE_MAX = 1.5\n",
    "VOL_MIN = 300\n",
    "VOL_OI_MIN = 2.0\n",
    "\n",
    "START_DATE_CUTOFF = \"2024-12-05\"\n",
    "END_DATE_CUTOFF   = \"2026-01-31\"\n",
    "\n",
    "HISTORY_LOOKBACK_DAYS = 14   # how far back to look for vol/OI trends\n",
    "HISTORY_1W_DAYS       = 7    # \"1 week\" window\n",
    "\n",
    "\n",
    "# ------------------ FILE NAMING ------------------\n",
    "base_date = datetime.now().strftime('%Y-%m-%d')\n",
    "prefix = f\"unusual_options_scan_{base_date}\"\n",
    "ext = \".csv\"\n",
    "\n",
    "# Find next index for filename (ignore summary files)\n",
    "existing_indices = []\n",
    "for fname in os.listdir('.'):\n",
    "    if fname.startswith(prefix) and fname.endswith(ext) and \"summary\" not in fname:\n",
    "        try:\n",
    "            num = int(fname[len(prefix)+1:-len(ext)])\n",
    "            existing_indices.append(num)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "next_index = max(existing_indices) + 1 if existing_indices else 1\n",
    "SAVE_CSV = f\"{prefix}_{next_index}{ext}\"\n",
    "SUMMARY_CSV = f\"{prefix}_{next_index}_summary{ext}\"\n",
    "\n",
    "print(f\"Next detailed file : {SAVE_CSV}\")\n",
    "print(f\"Next summary file  : {SUMMARY_CSV}\")\n",
    "\n",
    "\n",
    "# ------------------ TICKERS ------------------\n",
    "NASDAQ100 = [\n",
    "    \"AAPL\",\"MSFT\",\"NVDA\",\"AMZN\",\"META\",\"GOOGL\",\"GOOG\",\"TSLA\",\"AVGO\",\"COST\",\"AFRM\",\n",
    "    \"NFLX\",\"PEP\",\"ADBE\",\"AMD\",\"LIN\",\"TMUS\",\"CSCO\",\"QCOM\",\"TXN\",\"AMAT\",\n",
    "    \"INTU\",\"HON\",\"INTC\",\"BKNG\",\"SBUX\",\"MU\",\"AMGN\",\"PDD\",\"REGN\",\"LRCX\",\n",
    "    \"ADP\",\"ISRG\",\"ABNB\",\"MDLZ\",\"VRTX\",\"ASML\",\"GILD\",\"ADI\",\"PANW\",\"KLAC\",\n",
    "    \"PYPL\",\"CRWD\",\"CSX\",\"WDAY\",\"CHTR\",\"MAR\",\"NXPI\",\"ROP\",\"AEP\",\"KDP\",\n",
    "    \"MELI\",\"FTNT\",\"ORLY\",\"SNPS\",\"CDNS\",\"MNST\",\"CTAS\",\"DXCM\",\"PCAR\",\"LULU\",\n",
    "    \"MRVL\",\"MCHP\",\"ROST\",\"EXC\",\"ODFL\",\"ADSK\",\"ATVI\",\"IDXX\",\"EA\",\n",
    "    \"PAYX\",\"CTSH\",\"TEAM\",\"XEL\",\"WDAY\",\"DDOG\",\"ZS\",\"SPLK\",\"BKR\",\"ALGN\",\n",
    "    \"AZN\",\"CEG\",\"VRSK\",\"SIRI\",\"PDD\",\"LCID\",\"RIVN\",\"BIDU\",\"JD\",\"BMRN\",\n",
    "    \"DOCU\",\"VRSN\",\"NTES\",\"MRNA\",\"ANSS\",\"CSGP\",\"CHKP\",\"MTCH\",\"CRWD\",\"OKTA\",\n",
    "    \"NEE\",\"JNJ\",\"SMCI\",\"STZ\",\"TMQ\",\"PLTR\",\"XYZ\",\"HOOD\",\"ORCL\",\"UPST\",\n",
    "    \"TSM\",\"SHOP\",\"SPOT\",\"LLY\",\"HIMS\",\"UNH\",\"DELL\",\"COIN\",\"OSCR\",\"SNOW\",\n",
    "    \"QUBT\",\"RGTI\",\"CRWV\",\"RKLB\",\"BA\",\"QCOM\",\"PANW\",\"JPM\",\"GS\",\"BABA\",\"BIDU\",\n",
    "    \"USAR\",\"ONON\",\"VIX\",\"OKLO\",\"QS\",\"CRML\",\"MP\",\"QBTS\",\"JEF\",\"GKOS\",\"GSK\",\"AMGN\",\n",
    "    \"ROKU\",\"RH\",\"FCX\",\"DASH\",\"CHWY\",\"CCJ\",\"FI\",\"TEAM\",\"SBET\",\"METC\",\"AVAV\",\n",
    "    \"MTSR\",\"NTLA\",\"ALAB\",\"ALK\",\"PINS\",\"TEM\",\"AZN\",\"CE\",\"WWW\",\"TREX\",\"LVS\",\n",
    "    \"SNDK\",\"BBAI\",\"NNN\",\"QURE\",\"LENZ\",\"A\",\"SYM\",\"KSS\",\"EXEL\",\"MDB\", \"CFLT\", \"MSTR\", \"GEV\", \"SATS\"\n",
    "]\n",
    "\n",
    "TICKERS = sorted(list(dict.fromkeys(NASDAQ100)))  # Deduplicate\n",
    "\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def safe_option_chain(tkr, exp):\n",
    "    \"\"\"Return (calls, puts) for an expiry or (None, None) on failure.\"\"\"\n",
    "    try:\n",
    "        oc = tkr.option_chain(exp)\n",
    "        c = oc.calls.copy()\n",
    "        p = oc.puts.copy()\n",
    "        c[\"type\"] = \"CALL\"\n",
    "        p[\"type\"] = \"PUT\"\n",
    "        for df in (c, p):\n",
    "            df[\"expiration\"] = exp\n",
    "        return c, p\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def pick_expiries(all_exps):\n",
    "    \"\"\"\n",
    "    Filter expiries to be between START_DATE_CUTOFF and END_DATE_CUTOFF.\n",
    "    Then pick the nearest MAX_EXPIRIES_PER_TICKER - 1, plus Jan-2026 if present.\n",
    "    \"\"\"\n",
    "    low  = START_DATE_CUTOFF\n",
    "    high = END_DATE_CUTOFF\n",
    "\n",
    "    exps = [e for e in all_exps if low <= e <= high]\n",
    "    exps_sorted = sorted(exps)\n",
    "\n",
    "    # nearest expiries\n",
    "    chosen = exps_sorted[:max(0, MAX_EXPIRIES_PER_TICKER - 1)]\n",
    "\n",
    "    # include January 2026 expiry if exists\n",
    "    jan26 = [e for e in exps_sorted if e.startswith(\"2026-01\")]\n",
    "    if jan26:\n",
    "        pick = jan26[0]\n",
    "        if pick not in chosen:\n",
    "            chosen.append(pick)\n",
    "\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def load_history_trends(today_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load past scanner CSVs and compute base stats for the last 1w and 2w\n",
    "    per contractSymbol (avg volume & OI). We convert to relative changes\n",
    "    later inside add_trend_columns.\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "        contractSymbol, vol_1w_avg, vol_2w_avg, oi_1w_avg, oi_2w_avg\n",
    "    \"\"\"\n",
    "    today_ts = pd.to_datetime(today_str).normalize()\n",
    "    frames = []\n",
    "\n",
    "    pattern = \"unusual_options_scan_*.csv\"\n",
    "    for fname in glob.glob(pattern):\n",
    "        # skip summary files\n",
    "        if \"summary\" in fname:\n",
    "            continue\n",
    "\n",
    "        # expect: unusual_options_scan_YYYY-MM-DD_idx.csv\n",
    "        try:\n",
    "            basename = os.path.basename(fname)\n",
    "            core = basename[len(\"unusual_options_scan_\"):-4]  # strip prefix + \".csv\"\n",
    "            date_part = core.split(\"_\")[0]                    # YYYY-MM-DD\n",
    "            file_date = pd.to_datetime(date_part).normalize()\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # only look at strictly earlier days, within the lookback window\n",
    "        if file_date >= today_ts:\n",
    "            continue\n",
    "        days_ago = (today_ts - file_date).days\n",
    "        if days_ago > HISTORY_LOOKBACK_DAYS:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                fname,\n",
    "                usecols=[\"contractSymbol\", \"volume\", \"openInterest\"]\n",
    "            )\n",
    "        except Exception:\n",
    "            # if the file doesn't have those columns (e.g., older format), skip\n",
    "            continue\n",
    "\n",
    "        df[\"scan_date\"] = file_date\n",
    "        frames.append(df)\n",
    "\n",
    "    if not frames:\n",
    "        # No history – caller should handle empty df gracefully\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"contractSymbol\",\n",
    "                \"vol_1w_avg\", \"vol_2w_avg\",\n",
    "                \"oi_1w_avg\", \"oi_2w_avg\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    hist = pd.concat(frames, ignore_index=True)\n",
    "    hist[\"scan_date\"] = pd.to_datetime(hist[\"scan_date\"]).dt.normalize()\n",
    "    hist[\"days_ago\"] = (today_ts - hist[\"scan_date\"]).dt.days\n",
    "\n",
    "    # 1-week and 2-week subsets\n",
    "    hist_1w = hist[hist[\"days_ago\"] <= HISTORY_1W_DAYS]\n",
    "    hist_2w = hist[hist[\"days_ago\"] <= HISTORY_LOOKBACK_DAYS]\n",
    "\n",
    "    # averages per contractSymbol\n",
    "    g1 = hist_1w.groupby(\"contractSymbol\").agg(\n",
    "        vol_1w_avg=(\"volume\", \"mean\"),\n",
    "        oi_1w_avg=(\"openInterest\", \"mean\"),\n",
    "    )\n",
    "    g2 = hist_2w.groupby(\"contractSymbol\").agg(\n",
    "        vol_2w_avg=(\"volume\", \"mean\"),\n",
    "        oi_2w_avg=(\"openInterest\", \"mean\"),\n",
    "    )\n",
    "\n",
    "    trends = g1.join(g2, how=\"outer\").reset_index()\n",
    "    return trends\n",
    "\n",
    "\n",
    "def add_trend_columns(df: pd.DataFrame, today_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Join in 1w / 2w volume & OI increase metrics per contractSymbol.\n",
    "    - vol_1w_inc = (today_vol / avg_vol_last_7d)  - 1\n",
    "    - vol_2w_inc = (today_vol / avg_vol_last_14d) - 1\n",
    "    - oi_1w_inc  = (today_oi  / avg_oi_last_7d)   - 1\n",
    "    - oi_2w_inc  = (today_oi  / avg_oi_last_14d)  - 1\n",
    "    \"\"\"\n",
    "    trends = load_history_trends(today_str)\n",
    "\n",
    "    # If we have no history yet, just create empty columns and return\n",
    "    if trends.empty:\n",
    "        for col in [\"vol_1w_inc\", \"vol_2w_inc\", \"oi_1w_inc\", \"oi_2w_inc\"]:\n",
    "            df[col] = np.nan\n",
    "        return df\n",
    "\n",
    "    df = df.merge(trends, on=\"contractSymbol\", how=\"left\")\n",
    "\n",
    "    def rel_change(current, avg):\n",
    "        current = float(current) if pd.notna(current) else np.nan\n",
    "        avg = float(avg) if pd.notna(avg) and avg != 0 else np.nan\n",
    "        if np.isnan(current) or np.isnan(avg):\n",
    "            return np.nan\n",
    "        return (current / avg) - 1.0\n",
    "\n",
    "    df[\"vol_1w_inc\"] = df.apply(\n",
    "        lambda r: rel_change(r[\"volume\"], r.get(\"vol_1w_avg\", np.nan)), axis=1\n",
    "    )\n",
    "    df[\"vol_2w_inc\"] = df.apply(\n",
    "        lambda r: rel_change(r[\"volume\"], r.get(\"vol_2w_avg\", np.nan)), axis=1\n",
    "    )\n",
    "    df[\"oi_1w_inc\"] = df.apply(\n",
    "        lambda r: rel_change(r[\"openInterest\"], r.get(\"oi_1w_avg\", np.nan)), axis=1\n",
    "    )\n",
    "    df[\"oi_2w_inc\"] = df.apply(\n",
    "        lambda r: rel_change(r[\"openInterest\"], r.get(\"oi_2w_avg\", np.nan)), axis=1\n",
    "    )\n",
    "\n",
    "    # Drop intermediate avg columns so final CSV stays clean\n",
    "    for col in [\"vol_1w_avg\", \"vol_2w_avg\", \"oi_1w_avg\", \"oi_2w_avg\"]:\n",
    "        if col in df.columns:\n",
    "            del df[col]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def scan_ticker(ticker):\n",
    "    \"\"\"Return per-contract hits for a single ticker (today).\"\"\"\n",
    "    tkr = yf.Ticker(ticker)\n",
    "\n",
    "    try:\n",
    "        all_exps = tkr.options\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if not all_exps:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    exps = pick_expiries(all_exps)\n",
    "    rows = []\n",
    "\n",
    "    for exp in exps:\n",
    "        calls, puts = safe_option_chain(tkr, exp)\n",
    "        if calls is None:\n",
    "            continue\n",
    "\n",
    "        df = pd.concat([calls, puts], ignore_index=True)\n",
    "\n",
    "        # Ensure columns exist\n",
    "        for col in [\"lastPrice\", \"volume\", \"openInterest\", \"strike\"]:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "\n",
    "        df[\"vol_oi\"] = df[\"volume\"] / df[\"openInterest\"].replace(0, 1)\n",
    "\n",
    "        flt = (\n",
    "            (df[\"lastPrice\"] <= LAST_PRICE_MAX) &\n",
    "            (df[\"volume\"] >= VOL_MIN) &\n",
    "            (df[\"vol_oi\"] >= VOL_OI_MIN)\n",
    "        )\n",
    "\n",
    "        df = df.loc[\n",
    "            flt,\n",
    "            [\n",
    "                \"contractSymbol\", \"type\", \"strike\", \"lastPrice\", \"volume\",\n",
    "                \"openInterest\", \"vol_oi\", \"expiration\"\n",
    "            ]\n",
    "        ]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df[\"ticker\"] = ticker\n",
    "        df[\"score\"] = df[\"volume\"] * df[\"vol_oi\"]\n",
    "        rows.append(df)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)\n",
    "\n",
    "\n",
    "def build_ticker_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build per-ticker summary so it's human-readable:\n",
    "\n",
    "    Ticker, call_strike_min, call_strike_max, call_volume_sum, call_oi_sum,\n",
    "            put_strike_min,  put_strike_max,  put_volume_sum,  put_oi_sum,\n",
    "            call_oi_2w_inc_avg, put_oi_2w_inc_avg,\n",
    "            call_put_vol_ratio, call_put_oi_ratio,\n",
    "            call_n_contracts,  put_n_contracts,\n",
    "            total_volume, total_oi\n",
    "    \"\"\"\n",
    "    # group by ticker + type (CALL/PUT)\n",
    "    agg = (\n",
    "        df.groupby([\"ticker\", \"type\"])\n",
    "          .agg(\n",
    "              strike_min=(\"strike\", \"min\"),\n",
    "              strike_max=(\"strike\", \"max\"),\n",
    "              volume_sum=(\"volume\", \"sum\"),\n",
    "              oi_sum=(\"openInterest\", \"sum\"),\n",
    "              oi_2w_inc_avg=(\"oi_2w_inc\", \"mean\"),\n",
    "              vol_2w_inc_avg=(\"vol_2w_inc\", \"mean\"),\n",
    "              n_contracts=(\"contractSymbol\", \"nunique\"),\n",
    "          )\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # pivot types into columns\n",
    "    pivoted = agg.pivot(index=\"ticker\", columns=\"type\")\n",
    "    pivoted = pivoted.reset_index()\n",
    "\n",
    "    # Flatten MultiIndex columns: ('strike_min','CALL') -> 'call_strike_min'\n",
    "    flat_cols = []\n",
    "    for col in pivoted.columns.to_flat_index():\n",
    "        if isinstance(col, tuple):\n",
    "            metric, opt_type = col\n",
    "            if opt_type in (\"CALL\", \"PUT\"):\n",
    "                flat_cols.append(f\"{opt_type.lower()}_{metric}\")\n",
    "            else:\n",
    "                flat_cols.append(str(metric))\n",
    "        else:\n",
    "            flat_cols.append(col)\n",
    "    pivoted.columns = flat_cols\n",
    "\n",
    "    # Ensure missing columns are present\n",
    "    for col in [\n",
    "        \"call_strike_min\", \"call_strike_max\", \"call_volume_sum\", \"call_oi_sum\",\n",
    "        \"put_strike_min\",  \"put_strike_max\",  \"put_volume_sum\",  \"put_oi_sum\",\n",
    "        \"call_n_contracts\",\"put_n_contracts\",\n",
    "        \"call_oi_2w_inc_avg\",\"put_oi_2w_inc_avg\",\n",
    "    ]:\n",
    "        if col not in pivoted.columns:\n",
    "            if col.endswith(\"_inc_avg\"):\n",
    "                pivoted[col] = np.nan\n",
    "            else:\n",
    "                pivoted[col] = 0.0\n",
    "\n",
    "    # total flow + ratios\n",
    "    pivoted[\"total_volume\"] = pivoted[\"call_volume_sum\"] + pivoted[\"put_volume_sum\"]\n",
    "    pivoted[\"total_oi\"]     = pivoted[\"call_oi_sum\"] + pivoted[\"put_oi_sum\"]\n",
    "\n",
    "    # Avoid division by zero in ratios\n",
    "    pivoted[\"call_put_vol_ratio\"] = np.where(\n",
    "        pivoted[\"put_volume_sum\"] > 0,\n",
    "        pivoted[\"call_volume_sum\"] / pivoted[\"put_volume_sum\"],\n",
    "        np.nan,\n",
    "    )\n",
    "    pivoted[\"call_put_oi_ratio\"] = np.where(\n",
    "        pivoted[\"put_oi_sum\"] > 0,\n",
    "        pivoted[\"call_oi_sum\"] / pivoted[\"put_oi_sum\"],\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    # Sort: most active tickers first\n",
    "    pivoted = pivoted.sort_values(\"total_volume\", ascending=False)\n",
    "\n",
    "    # Reorder columns into a nice human-readable layout\n",
    "    cols = [\n",
    "        \"ticker\",\n",
    "        \"call_strike_min\", \"call_strike_max\", \"call_volume_sum\", \"call_oi_sum\",\n",
    "        \"put_strike_min\",  \"put_strike_max\",  \"put_volume_sum\",  \"put_oi_sum\",\n",
    "        \"call_oi_2w_inc_avg\", \"put_oi_2w_inc_avg\",\n",
    "        \"call_put_vol_ratio\", \"call_put_oi_ratio\",\n",
    "        \"call_n_contracts\", \"put_n_contracts\",\n",
    "        \"total_volume\", \"total_oi\",\n",
    "    ]\n",
    "    cols = [c for c in cols if c in pivoted.columns]\n",
    "    pivoted = pivoted[cols]\n",
    "\n",
    "    return pivoted\n",
    "\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "def main():\n",
    "    all_hits = []\n",
    "\n",
    "    max_workers = min(20, len(TICKERS))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(scan_ticker, tk): tk for tk in TICKERS}\n",
    "\n",
    "        for i, future in enumerate(as_completed(futures), 1):\n",
    "            tk = futures[future]\n",
    "            try:\n",
    "                hits = future.result()\n",
    "                if not hits.empty:\n",
    "                    all_hits.append(hits)\n",
    "                    print(f\"[{i:3d}/{len(TICKERS)}] ✅ {tk} — found {len(hits)} matches\")\n",
    "                else:\n",
    "                    print(f\"[{i:3d}/{len(TICKERS)}] {tk} — no matches\")\n",
    "            except Exception as e:\n",
    "                print(f\"[{i:3d}/{len(TICKERS)}] ❌ {tk} error: {e}\")\n",
    "\n",
    "    if not all_hits:\n",
    "        print(\"No matches found. Lower VOL_MIN or VOL_OI_MIN?\")\n",
    "        return\n",
    "\n",
    "    df = pd.concat(all_hits, ignore_index=True)\n",
    "\n",
    "    # Add 1w/2w volume/OI increase metrics (investor trend)\n",
    "    df = add_trend_columns(df, base_date)\n",
    "\n",
    "    # Save detailed contract-level CSV\n",
    "    detailed_cols = [\n",
    "        \"ticker\",\"type\",\"strike\",\"lastPrice\",\"volume\",\n",
    "        \"openInterest\",\"vol_oi\",\"expiration\",\"contractSymbol\",\"score\",\n",
    "        \"vol_1w_inc\",\"vol_2w_inc\",\"oi_1w_inc\",\"oi_2w_inc\",\n",
    "    ]\n",
    "    detailed_cols = [c for c in detailed_cols if c in df.columns]\n",
    "    df[detailed_cols].to_csv(SAVE_CSV, index=False)\n",
    "    print(f\"\\nSaved {len(df)} detailed rows → {SAVE_CSV}\")\n",
    "\n",
    "    # Build per-ticker summary for human reading\n",
    "    summary = build_ticker_summary(df)\n",
    "    summary.to_csv(SUMMARY_CSV, index=False)\n",
    "    print(f\"Saved {len(summary)} ticker summaries → {SUMMARY_CSV}\")\n",
    "\n",
    "    # Print a small sample to console so you can quickly read direction\n",
    "    print(\"\\n=== Top 25 tickers by total volume (summary) ===\")\n",
    "    print(summary.head(25).to_string(index=False))\n",
    "\n",
    "    # Optional: old-style top 10 by score\n",
    "    per_ticker = (\n",
    "        df.groupby(\"ticker\")[\"score\"]\n",
    "          .max()\n",
    "          .reset_index()\n",
    "          .sort_values(\"score\", ascending=False)\n",
    "    )\n",
    "    top10 = per_ticker[\"ticker\"].head(10).tolist()\n",
    "    print(\"\\n=== Old-style Top 10 tickers by max score ===\")\n",
    "    for _, row in per_ticker[per_ticker[\"ticker\"].isin(top10)].iterrows():\n",
    "        print(f\"{row['ticker']:>5}  score={row['score']:.1f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce1131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
